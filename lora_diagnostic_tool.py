import os
import json
import torch
import logging
from pathlib import Path
from safetensors import safe_open
from safetensors.torch import save_file
from diffusers import StableDiffusion3Pipeline
from typing import Dict, Any, Optional

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class LoRADiagnosticTool:
    def __init__(self):
        self.sd3_layer_mapping = {
            # Transformer layers mapping
            "transformer.transformer_blocks": "transformer.transformer_blocks",
            "transformer.pos_embed": "transformer.pos_embed", 
            "transformer.x_embedder": "transformer.x_embedder",
            "transformer.y_embedder": "transformer.y_embedder",
            "transformer.context_embedder": "transformer.context_embedder",
            "transformer.t_embedder": "transformer.t_embedder",
            "transformer.norm_out": "transformer.norm_out",
            "transformer.proj_out": "transformer.proj_out"
        }
    
    def diagnose_lora_files(self, lora_dir: str) -> Dict[str, Any]:
        """è¯Šæ–­LoRAæ–‡ä»¶ç»“æ„å’Œå†…å®¹"""
        diagnosis = {
            "files_found": [],
            "total_tensors": 0,
            "lora_layers": [],
            "weight_info": {},
            "issues": []
        }
        
        lora_path = Path(lora_dir)
        if not lora_path.exists():
            diagnosis["issues"].append(f"LoRAç›®å½•ä¸å­˜åœ¨: {lora_dir}")
            return diagnosis
        
        # æ£€æŸ¥æ–‡ä»¶
        safetensor_files = list(lora_path.glob("*.safetensors"))
        if not safetensor_files:
            diagnosis["issues"].append("æœªæ‰¾åˆ°.safetensorsæ–‡ä»¶")
            return diagnosis
        
        diagnosis["files_found"] = [str(f) for f in safetensor_files]
        
        # åˆ†ææ¯ä¸ªæ–‡ä»¶
        for file_path in safetensor_files:
            try:
                with safe_open(file_path, framework="pt", device="cpu") as f:
                    tensor_names = f.keys()
                    diagnosis["total_tensors"] += len(tensor_names)
                    
                    for name in tensor_names:
                        tensor = f.get_tensor(name)
                        diagnosis["weight_info"][name] = {
                            "shape": list(tensor.shape),
                            "dtype": str(tensor.dtype),
                            "non_zero_ratio": (tensor != 0).float().mean().item(),
                            "abs_mean": tensor.abs().mean().item()
                        }
                        
                        # æ£€æŸ¥æ˜¯å¦ä¸ºLoRAå±‚
                        if any(lora_key in name.lower() for lora_key in ["lora_a", "lora_b", "alpha"]):
                            diagnosis["lora_layers"].append(name)
                            
            except Exception as e:
                diagnosis["issues"].append(f"è¯»å–æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {str(e)}")
        
        return diagnosis
    
    def fix_lora_adapter_config(self, lora_dir: str):
        """ä¿®å¤adapter_config.jsonæ–‡ä»¶"""
        config_path = Path(lora_dir) / "adapter_config.json"
        
        # æ ‡å‡†çš„SD3 LoRAé…ç½®
        standard_config = {
            "base_model_name_or_path": "stabilityai/stable-diffusion-3-medium-diffusers",
            "library_name": "diffusers",
            "peft_type": "LORA",
            "target_modules": [
                "to_k",
                "to_q", 
                "to_v",
                "to_out.0",
                "proj_in",
                "proj_out",
                "ff.net.0.proj",
                "ff.net.2"
            ],
            "task_type": "DIFFUSION"
        }
        
        if config_path.exists():
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    existing_config = json.load(f)
                print(f"ç°æœ‰é…ç½®: {existing_config}")
            except:
                print("æ— æ³•è¯»å–ç°æœ‰é…ç½®æ–‡ä»¶")
        
        # å†™å…¥æ ‡å‡†é…ç½®
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(standard_config, f, indent=2)
        
        print(f"âœ… å·²æ›´æ–°adapter_config.json: {config_path}")
    
    def convert_weights_format(self, input_dir: str, output_dir: str):
        """è½¬æ¢æƒé‡æ ¼å¼ä»¥ç¡®ä¿å…¼å®¹æ€§"""
        input_path = Path(input_dir)
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        # æ”¶é›†æ‰€æœ‰æƒé‡
        all_tensors = {}
        
        for safetensor_file in input_path.glob("*.safetensors"):
            print(f"å¤„ç†æ–‡ä»¶: {safetensor_file}")
            
            with safe_open(safetensor_file, framework="pt", device="cpu") as f:
                for key in f.keys():
                    tensor = f.get_tensor(key)
                    
                    # ç¡®ä¿æƒé‡åç§°ç¬¦åˆDiffusersæ ¼å¼
                    converted_key = self.convert_key_name(key)
                    all_tensors[converted_key] = tensor
                    print(f"  {key} -> {converted_key} | Shape: {tensor.shape}")
        
        if all_tensors:
            # ä¿å­˜è½¬æ¢åçš„æƒé‡
            output_file = output_path / "adapter_model.safetensors"
            save_file(all_tensors, output_file)
            print(f"âœ… å·²ä¿å­˜è½¬æ¢åçš„æƒé‡: {output_file}")
            
            # å¤åˆ¶é…ç½®æ–‡ä»¶
            self.fix_lora_adapter_config(str(output_path))
            
            return str(output_path)
        else:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„å¼ é‡")
            return None
    
    def convert_key_name(self, key: str) -> str:
        """è½¬æ¢æƒé‡é”®åä»¥åŒ¹é…Diffusersæ ¼å¼"""
        # å¸¸è§çš„è½¬æ¢è§„åˆ™
        conversions = {
            # å¤„ç†ä¸åŒçš„å‘½åçº¦å®š
            "lora_unet_": "",
            "lora_te_": "text_encoder.",
            "lora_te1_": "text_encoder.",
            "lora_te2_": "text_encoder_2.",
            "lora_te3_": "text_encoder_3.",
        }
        
        converted = key
        for old, new in conversions.items():
            if old in converted:
                converted = converted.replace(old, new)
        
        # ç¡®ä¿transformerå±‚è·¯å¾„æ­£ç¡®
        if "transformer_blocks" in converted:
            # æ ‡å‡†åŒ–transformerå—çš„è·¯å¾„
            parts = converted.split(".")
            if "transformer_blocks" in parts:
                idx = parts.index("transformer_blocks")
                if idx + 1 < len(parts):
                    # ç¡®ä¿æ ¼å¼ä¸º transformer.transformer_blocks.{num}.{layer}
                    if not converted.startswith("transformer."):
                        converted = "transformer." + converted
        
        return converted
    
    def test_lora_loading(self, model_path: str, lora_path: str) -> bool:
        """æµ‹è¯•LoRAåŠ è½½"""
        try:
            print(f"ğŸ”„ åŠ è½½åŸºç¡€æ¨¡å‹: {model_path}")
            pipe = StableDiffusion3Pipeline.from_pretrained(
                model_path,
                torch_dtype=torch.float16,
                variant="fp16",
                safety_checker=None,
                requires_safety_checker=False
            )
            
            print(f"ğŸ”„ åŠ è½½LoRAæƒé‡: {lora_path}")
            pipe.load_lora_weights(lora_path)
            
            # æ£€æŸ¥æ˜¯å¦æˆåŠŸåŠ è½½
            lora_found = False
            for name, module in pipe.transformer.named_modules():
                if hasattr(module, 'lora_A') or hasattr(module, 'lora_B'):
                    print(f"âœ… æ£€æµ‹åˆ°LoRAå±‚: {name}")
                    lora_found = True
                elif 'lora' in name.lower():
                    print(f"ğŸ” å¯èƒ½çš„LoRAç›¸å…³å±‚: {name}")
            
            # æ£€æŸ¥pipeçš„loraçŠ¶æ€
            if hasattr(pipe, '_lora_scale') or hasattr(pipe, 'get_active_adapters'):
                try:
                    active_adapters = pipe.get_active_adapters() if hasattr(pipe, 'get_active_adapters') else []
                    print(f"ğŸ” æ´»è·ƒçš„é€‚é…å™¨: {active_adapters}")
                    if active_adapters:
                        lora_found = True
                except:
                    pass
            
            return lora_found
            
        except Exception as e:
            print(f"âŒ åŠ è½½æµ‹è¯•å¤±è´¥: {str(e)}")
            return False
    
    def full_diagnostic_and_fix(self, lora_dir: str, model_path: str, output_dir: Optional[str] = None):
        """å®Œæ•´çš„è¯Šæ–­å’Œä¿®å¤æµç¨‹"""
        print("=" * 60)
        print("ğŸ” å¼€å§‹LoRAè¯Šæ–­å’Œä¿®å¤")
        print("=" * 60)
        
        # 1. è¯Šæ–­åŸå§‹æ–‡ä»¶
        print("\nğŸ“‹ æ­¥éª¤1: è¯Šæ–­åŸå§‹LoRAæ–‡ä»¶")
        diagnosis = self.diagnose_lora_files(lora_dir)
        
        print(f"æ‰¾åˆ°æ–‡ä»¶: {len(diagnosis['files_found'])}")
        for file in diagnosis['files_found']:
            print(f"  - {file}")
        
        print(f"æ€»å¼ é‡æ•°: {diagnosis['total_tensors']}")
        print(f"LoRAå±‚æ•°: {len(diagnosis['lora_layers'])}")
        
        if diagnosis['issues']:
            print("âš ï¸  å‘ç°é—®é¢˜:")
            for issue in diagnosis['issues']:
                print(f"  - {issue}")
        
        # 2. ä¿®å¤é…ç½®
        print("\nğŸ”§ æ­¥éª¤2: ä¿®å¤é…ç½®æ–‡ä»¶")
        self.fix_lora_adapter_config(lora_dir)
        
        # 3. å¦‚æœéœ€è¦ï¼Œè½¬æ¢æ ¼å¼
        if output_dir:
            print(f"\nğŸ”„ æ­¥éª¤3: è½¬æ¢æƒé‡æ ¼å¼åˆ° {output_dir}")
            converted_path = self.convert_weights_format(lora_dir, output_dir)
            if converted_path:
                lora_dir = converted_path
        
        # 4. æµ‹è¯•åŠ è½½
        print("\nğŸ§ª æ­¥éª¤4: æµ‹è¯•LoRAåŠ è½½")
        success = self.test_lora_loading(model_path, lora_dir)
        
        if success:
            print("ğŸ‰ LoRAåŠ è½½æˆåŠŸ!")
        else:
            print("âŒ LoRAåŠ è½½ä»ç„¶å¤±è´¥")
            print("\nğŸ’¡ å»ºè®®:")
            print("1. æ£€æŸ¥åŸå§‹LoRAæ–‡ä»¶æ˜¯å¦ä¸ºSD3æ ¼å¼")
            print("2. ç¡®è®¤æ¨¡å‹è·¯å¾„æ­£ç¡®")
            print("3. å°è¯•ä½¿ç”¨ä¸åŒçš„è½¬æ¢å‚æ•°")
        
        return success

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # é…ç½®è·¯å¾„
    config = {
        'official_model_path': "/root/autodl-tmp/models/stabilityai--stable-diffusion-3-medium-diffusers/",
        'lora_model_dir': "/home/lora_sd3_train_logs_0524_1600_0525_1600/lora_final/",
        'output_dir': "/home/lora_sd3_train_logs_0524_1600_0525_1600/lora_final_converted//"  # å¯é€‰ï¼šè¾“å‡ºä¿®å¤åçš„LoRA
    }
    
    # åˆ›å»ºè¯Šæ–­å·¥å…·
    diagnostic = LoRADiagnosticTool()
    
    # è¿è¡Œå®Œæ•´è¯Šæ–­å’Œä¿®å¤
    success = diagnostic.full_diagnostic_and_fix(
        lora_dir=config['lora_model_dir'],
        model_path=config['official_model_path'],
        output_dir=config['output_dir']
    )
    
    if success:
        print("\nâœ… ç°åœ¨å¯ä»¥æ­£å¸¸ä½¿ç”¨LoRAäº†!")
    else:
        print("\nâŒ éœ€è¦è¿›ä¸€æ­¥æ£€æŸ¥åŸå§‹LoRAæ–‡ä»¶")